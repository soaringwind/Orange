# 模型度量标准

## 混淆矩阵

<img src="https://img2018.cnblogs.com/common/721540/202002/721540-20200227190850638-263689169.png" alt="img" style="zoom: 80%;" />

TP指的是正样本识别为正样本，TN指的是负样本识别为负样本。实际中，希望TP和TN越多越好，但结果往往不是，所以需要用各种指标来衡量系统的好坏。

![img](https://ask.qcloudimg.com/http-save/1692602/nek3uj4izl.png?imageView2/2/w/1620)

准确率：正确分类样本与所有样本的比率，这个指标是最为严格的。正样本和负样本都需要正确分类，个人比较喜欢用。

精确率/查准率（Precision）：模型预测是正样本中模型预测正确的比率。只考虑模型预测中正样本正确分类比率，负样本考虑较少，类似于挑西瓜中就想要挑到好的。只想知道我挑到的好的里面有多少是好的。适用的场景：如果错误样本被预测为正样本的代价很高，就需要用这个比率，比如垃圾邮件分类，把非垃圾邮件归到垃圾邮件代价就很高。

召回率/查全率（Recall）：在所有正样本中被正确预测的比率。也就是原本是正样本，预测也是正样本占所有正样本比率。也就是挑西瓜中，本来是好西瓜，挑到好西瓜是好西瓜的比率。适用场景：如果正样本被预测为错误的代价很高，就需要用这个比率，比如新冠疫情，如果患病者被预测为未患病者就很糟糕，就需要用这个比率。

特异度：在所有负样本中被正确预测的比率。

## 多标签分类损失
Hamming loss（汉明损失）

```
它统计了误分类标签（这里的误分类统计，统计的是错误的标签个数，比如一个样本是100，预测为000，则损失为1/3）的个数占整个数据的比例。它有个缺陷，如果每个样本本身的标签很稀疏，那么即使每个样本全部预测为0，该损失也会很小。
比如这一类数据库的标签很多，但是每个样本的标签比较少，因此表示起来就比较稀疏，这样如果对所有样本的标签都预测为0，损失也不会很大。
```

https://www.zhihu.com/question/358811772


# 深度可分离卷积

深度可分离卷积depthwise separable convolution，由depthwise(DW)和pointwise(PW)两个部分结合起来，用来提取特征feature map相比常规的卷积操作，其参数数量和运算成本比较低。实际上就是把一次卷积做的事情，拆成两次，来降低参数量。
常规卷积操作如下图，输入的channel数量为3，想要得到4个channel的feature map，那需要的模板的数量实际上是12个3×3的模板，有108个参数需要学习，参数实际上是相对较多的。

![image](https://user-images.githubusercontent.com/26198992/177484110-729ff874-fc3e-453b-b5dd-55380e75821f.png)

深度可分离卷积操作，由两个部分组成，首先是逐通道卷积，也就是输入和输出的通道数是相同的，这时候需要的参数量是27个，之后进行逐点卷积，这个使用的是1×1的模板来调整通道数，输入3通道，输出的是4通道，因此需要的参数量是12个，加在一起也不过39个，参数量远远低于之前的常规卷积操作。
1. 逐通道卷积

![image](https://user-images.githubusercontent.com/26198992/177484224-b9ced2b4-3c27-4117-a92e-2b4c2d16149f.png)

2. 逐点卷积

![image](https://user-images.githubusercontent.com/26198992/177484263-e3fa3192-32e5-4a7f-a5cd-600aa9db6cef.png)

通过计算参数量可以发现，使用深度可分离卷积的参数的数量明显减少。

# ViT
在提取的特征矩阵之前，加上一个cls_token的标志，该位对应向量可以作为整句话的语义表示，从而用于下游的分类任务等。这是因为cls_token位本身没有语义，经过多层attention，得到的是attention后所有词的加权平均，相比其他正常词，可以更好的表征句子语义。ViT的关键就是如何把图像使用Transformer来进行分类，如果直接把图像完全展开，直接的问题就是计算量太大了。还有一点是，ViT的表现如果想要超过CNN，那需要拥有足够多的数据进行预训练。另外，ViT只使用了Transformer中的Encoder的部分，下面介绍ViT的流程。

![img](https://pic4.zhimg.com/80/v2-5afd38bd10b279f3a572b13cda399233_1440w.jpg)

ViT流程：

1. Patch embedding：对一张图进行裁剪，ViT使用的是卷积，SwinTransformer则是用unfold来裁剪。比如图片大小为224×224，用步长为16，窗口为16的卷积核，就可以把图像分为14×14个patch，每个patch的特征向量是16×16×3长度，因此输入序列的长度就是196，而每个序列的特征向量长度就是768。这里还要加入一个之前说到的分类向量cls，因此最终的维度是197×768。这就把视觉问题转化成了一个seq2seq问题。
2. Positional encoding：由于图像不同的位置同样可能存在信息，所以还需要有位置编码信息。这里是把位置编码直接加到之前的embedding结果上，并且位置编码让机器自己去学习。
3. LN/multi-head attention/LN：LN输出维度不会变仍旧是197×768。多头自注意力时，先把输入映射到q，k，v，如果只有一个头，那么qkv的维度都是197×768，如果有12个头（768/12=64），则qkv的维度是197×64，一共有12组qkv，最后再将12组qkv的输出拼接起来，输出维度就是197×768，然后再经过一层LN。
4. MLP：将维度放大再缩小回去，197×3072放大为3072，再缩小变为197×768。

这里看出，经过一个block的输出和最开始的输入是一样的维度，因此可以堆叠多个block，最后将第一维的cls作为输出，后面接一个MLP进行图片分类。

这里拿cifar10的数据集使用ViT来分类的时候，有两个问题，第一个训练时间过长，第二个模型容易过拟合，这两个问题都是由于模型过于复杂，往往训练到最后损失已经很小，但是在验证集上的效果并不好。这个问题在网上查过，主要有两个方法，第一个是增加训练的数据量，还没有尝试过，第二个是降低模型复杂度，比如添加dropout，这个尝试过，但是带来一个新的问题，模型收敛速度变慢，第三个办法和第一个类似先在大数据集上训练，再在小的数据集上进行微调。

# Swin Transformer

先说下，这个模型尽管说起来很强大，但是本质上还是把Transformer用在分类上，因此基本流程还是很像，还有self attention的过程。

# self-attention原理
自注意力机制（self-attention）最开始用在NLP任务中，它可以有效的解决RNN和LSTM带来的记忆消退问题。RNN（循环神经网络）它最大的问题在于两点，第一是无法并行计算，只能够等待前一个计算完之后，再计算下一个输出，第二是无法将最前面的信息跟随着传递到最后面去（也就是记忆消退问题）。在此基础上提出attention机制，它首先是考虑全局的影响，之后根据训练来找到需要注意的地方，也就是自适应的找到聚焦点。如下图。

![image](https://user-images.githubusercontent.com/26198992/177941193-149f8549-1bd1-48e3-abf8-0c280d40de16.png)

## attention原理
注意力机制的提出要早于自注意力机制，它实际上解决的问题是如何分配注意力问题，也是去计算attention值基本和后面的self-attention的计算过程一样。本质过程如图。

![image](https://user-images.githubusercontent.com/26198992/177942431-8420f8fc-ed7d-4ffe-b0fc-6f2a0b7ac676.png)

query和key计算相似度，之后将其归一化，归一化之后再和value值加权求和，即可得到attention的值。计算如图。

![image](https://user-images.githubusercontent.com/26198992/177942753-98fca16c-0351-4515-b13c-82e41186b4a4.png)

## self-attention原理
self-attention和attention机制在本质上基本一样，他们的区别在于attention是target和source做attention计算，而self-attention是source和source本身计算attention也就是计算自己各个部分的attention分数。计算过程如图。

![image](https://user-images.githubusercontent.com/26198992/177944172-f3a352f6-555b-48ef-b1fd-7903915b2238.png)

# Transformer

## end-to-end

end-to-eng实际上就是端到端，它指的就是输入的是原始数据，输出的是最后的结果。而在最初的机器学习当中，输入的往往是在原始数据中提取的特征，这种时候分类的结果十分取决于提取特征的好坏，所以以前的机器学习又被称为特征工程（feature engineering）。

好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。

缺点：往往需要大量的训练数据。比如人脸识别，无法提前知道人脸会在何处出现，也不知道大小是多少，很难直接从原始图像中直接判断，这时候就需要分步来完成。

## transformer

![img](https://upload-images.jianshu.io/upload_images/1667471-926eb6cb29978dad.png?imageMogr2/auto-orient/strip|imageView2/2/w/347/format/webp)


## Swin Transformer
# 代码
https://github.com/berniwal/swin-transformer-pytorch
https://zhuanlan.zhihu.com/p/542675669
https://zhuanlan.zhihu.com/p/361366090

# mask部分理解
循环移位是为了让图像分割方便，因为移位之后，可以和之前一样来进行分割。
实际上这里的mask是因为在之前做了一次循环移位，也就是把较远位置的图像移到了一起，所以互相之间不能计算相关性，要把结果给隐去，所以使用了mask。
https://itcn.blog/p/0856239139.html

# einsum（爱因斯坦求和）
https://zhuanlan.zhihu.com/p/44954540

# 整理
https://www.cxybb.com/article/weixin_44485421/119425070
https://zhuanlan.zhihu.com/p/384727327

# 目标检测
知识点：
1. IOU计算：两个区域交集和并集的比例。https://zhuanlan.zhihu.com/p/111013447
2. 人脸数据集与非人脸数据集准备：在人脸附近随机取区域，把取到的区域和人脸区域进行IOU计算，小于一定比例的认为是非人脸。
3. 级联思想：不会一次就判断该区域是否为人脸，而是先删去大量不是人脸的区域，再层层严格的确定一定为人脸的区域。
4. 非极大值抑制：需要在一个区域内多个重叠框输出为一个框。

## Adaboost
设计出了一个很简单的检测人脸的模板特征（Harr特征），该特征由5个局部特征组合而成，通过检测这五个不同大小的局部特征，可以准确判断出人脸。为了加快计算Harr特征，提出了积分图的概念，有了积分图，计算Harr特征就仅仅只需要几次加减法即可。有了Harr特征之后，它用到了级联的思想也就是Adaboost，通过构建决策树模型，构建出多个强分类器，不断把非人脸剔除，最终留下人脸。

## MTCNN
设计出了三个网络用来进行人脸的检测。其实整体流程和前面的Adaboost非常相似，但是这里用的是神经网络的方式来进行检测，并且用了三个网络，形式上类似级联的思想。
知识点：
1. 提出三个网络，Pnet，Rnet和Onet。每个网络检测图像的尺寸不同，从大到小为12，24和48。每个神经网络都不是很复杂，因此很容易收敛。
2. 使用级联的思想，把复杂问题简单化，因此对设备的要求不高。
3. 检测的时候不断缩小图像的尺寸，构建出图像金字塔，通过第一个Pnet网络可以过滤掉大量不是人脸的区域。之后根据Pnet网络的结果去拿到相应的区域，再输入到Rnet中，再过滤掉大量非人脸区域，再取到对应的区域，再输入到Onet网络中，进行最后的判断。
https://blog.csdn.net/ssunshining/article/details/108903871

# 目标识别
目标识别任务是给出一组特征数据，需要给出该数据所对应的标签。这里CV中最常用的就是卷积神经网络。在实际任务中用到的是一下几个网络。

## VGG
通过组合多个小的卷积核来得到和一个大的卷积核一样的感受野，现在常常用来做特征的提取。因为使用传统的VGG有很多问题，比如直筒式模型找到的特征有限，计算速度较慢。但是在我们的任务中，VGG网络已经表现的足够好。
知识点：
1. 感受野大小：VGG使用的全部是尺寸为3的卷积核，通过组合多个小的卷积核来得到和一个大的卷积核一样大小的感受野。2个3的卷积核和5的卷积核感受野相同，3个3的卷积核和7的卷积核感受野相同。
2. 使用尺寸为2的最大池化来减小窗口的大小，并且随着窗口尺寸的减半，通道数加倍。
3. 引入了全局平均池化的概念，也就是把最后得到的特征图根据通道数直接平均得到一个和通道数相同的向量。

## SENet
在之前的卷积中不断的扩大通道数的目的是为了检测到更多的特征，而每次往下传递的时候，每个通道也就是特征的权重都是相同的，如果每次能够把重要的特征权重提高，不重要的特征权重下降，理论上可以提高模型性能。SeNet就是做这个事情，它分为sequeeze压缩特征块，和excitation激发特征块组成。其实网络的构建非常简单，全局平均池化得到每个特征的值，再接上两层全连接层，最后输出每个通道的权重值。
知识点：
1. SeNet可以很好的嵌入到各个网络中去。
2. 它的思想类似于计算注意力，注意力也是去计算一个权重。后面的CBAM思想很类似。
https://zhuanlan.zhihu.com/p/32702350

## CBAMNet
CBAM的思想和前面的SeNet网络其实是很相似的，它提出一种简单有效的注意力模块。它主要提出两个方面，第一个是通道间的注意力模块（CAM），第二个是空间注意力模块（SAM）。其中CAM和之前的SeNet很相似，首先对每一个特征进行全局池化（最大和平均）之后进入MLP得到通道间注意力，SAM则是对特征图上每一个像素，基于channel进行池化（最大和平均），最后得到两个特征图，再进行尺寸为7的卷积操作，降维成1个通道，最后经过sigmoid得到空间注意力。
知识点：
1. 两种注意力机制计算。
2. 引入注意力机制的确让神经网络更关注我们认为重要的位置。
3. 同样，它也可以融入到各个网络中去。

## SwinT
之前的方法基本上都是在用卷积处理，也用到了很多的注意力机制，但注意力机制提到最多的还是在语音识别任务中，也就是去计算不同tokens之间的相关性，因此有了ViT。ViT将图片进行分割，使得识别任务也能够使用注意力机制来计算。ViT采取的做法是将图片分割为n个尺寸为16的图片块，接下来将每个图片块映射为768维token，这样就把计算机视觉任务改成了一个语义识别任务。但是实作的时候发现，使用这种方法必须先进行大量的预运算，才能够得到超过CNN的结果，如果直接训练，则效果不如CNN，并且该网络需要很长时间的训练，不易收敛。
尽管ViT成功的将计算机识别任务转换成了语义识别任务，但是还是存在很多，比如模型过于复杂，在小数据集上表现一般，且该方法无法得到图像多尺度的信息。SwinT和ViT类似，都是将图像识别任务转换成了语义识别任务，但是ViT更像是硬套，而SwinT则有更多的图像本身信息。SwinT会对图像进行多次的降采样，因此可以得到图像多尺度的信息。其次，SwinT进行的注意力计算，是集中在每个局部的小窗口上，因此注意力的运算量大大减小。同时为了得到全局的注意力信息，会对窗口进行一次滑动，滑动之后再进行一次注意力的计算，以此得到全局的注意力信息。

## FETrans
这个网络模型是中移提出，来解决干扰单标签及多标签的分类任务。如果仅仅是单标签，使用VGG或者GoogLeNet可以得到比较的结果，而如果是多标签分类，单用VGG则效果不是那么优良，如果外场实际使用则效果还需要提升，因此提出了很多方法，比如前面的SeNet，CBAM等等。同时，还尝试使用Transformer来进行，实验表明，如果单单用Transformer效果并不好，且收敛时间很长。因此，提出了一种网络，首先对数据进行卷积，得到更有特征的干扰数据，之后再将数据进行堆叠，之后使用Transformer来进行分类。并且，不是完全的硬套Transformer，位置编码等信息，我们这里并不需要，因此都可以删除。在大量数据的训练下，多标签分类任务，FETrans模型效果会更好一些。

## 常见问题
1. 感受野计算

   - 两个尺寸为3的小卷积模板的感受野和尺寸为5的卷积模板相同。
   - 三个尺寸为3的小卷积模板的感受野和尺寸为7的卷积模板相同。

2. IOU计算

   - 制定好框的四个点位置，很好计算，两个min，两个max。

   - 有多种IOU，之所以有这么多的IOU是因为想用IOU来直接进行梯度回传，所以需要衡量相同IOU下，不同框的偏移程度，如GIOU。

     ```
     IOU: 
     GIOU: 
     ```

     

3. 深浅copy

   可变数据结构和不可变数据结构的区别，在python中列表，字典这种都属于可变数据结构，而元组，字符串这种都属于不可变数据结构。如果使用copy方法的时候，可变数据结构会拿到新的内存地址，但是如果可变数据结构中还有可变数据结构，那么里面那层可变数据结构还是会使用之前的内存地址，因此一旦发生改变，还是会一起改变。这种都属于浅copy，只有调用了copy库里面的deepcopy才是深copy。

   - 浅copy：可变数据结构内存地址会发生变化，但如果里面嵌套了可变数据结构，则嵌套的可变数据结构内存地址未发生改变。例子，copy列表之后再对列表里的不可变数据结构元素进行修改是不会发生联动变化的。
   - 深copy：所有的内存地址都发生了变化。深copy列表之后，无论列表里面的不可变数据结构和可变数据结构都不会发生变化。

4. 多进程和多线程的区别

   进程是资源分配的最小单位，线程是CPU调度的最小单位。

   - 多进程：计算密集型。需要大量使用CPU。优点，内存隔离，单个进程异常不会导致整个应用崩溃。缺点，共享数据麻烦。
   - 多线程：IO密集型。不用CPU。优点，提高系统的并行性，开销小，有大量IO操作时，有利于提高系统的并行性。缺点，没有内存隔离，单个线程崩溃会导致整个应用推出。

5. python中生成器和迭代的区别

   迭代器就是迭代操作，任何实现了__next__的方法的都称为迭代器，它类似列表，可以使用for循环进行遍历。与列表的区别在于，不会一次将所有的元素加载到内存，而是一种懒加载的方式，只有调用next方法的时候，才会加载。
   生成器，其实本质还是迭代器，只是里面的return关键字变成yield所以使用next的时候就会去加载。

5. CV问题

   ResNet思想及能解决的问题：
      - 在网络中增加了直连通道，允许原始输入信息直接传到后面的层中，因此只需要学习原始输入信息到输出信息的差值即可。
      - 解决梯度消失问题，有了直连通道，使得梯度可以正常回传。
      - 构建更深层的网络。

   ```
   怎样判断和防止过拟合（高频）：过拟合指的是，模型在训练集上表现很好，但是在测试集上表现效果差，模型的泛化能力弱。在模型训练的过程中，通常会留下部分验证集，当模型在验证集上的误差已经不再下降，但模型的loss还在下降的时候就要考虑是否出现了过拟合。
      防止过拟合方法：
         1. 增加数据，也就是数据增强，通过有效增加训练数据，给训练数据加上一部分误差，比如cv中对图像的遮挡，改变颜色等等方法。最理想情况，模型见到了所有可能的数据，那么即使过拟合也无所谓了，只要能正确分类即可。
         2. 提前停止，通过绘制验证集准确率和训练集误差，在验证集准确率不怎么变化的时候，考虑提前停下训练，避免过拟合。
         3. 正则化，分为L1正则化，也就是对所有的权重取绝对值的和，导致的结果就是产生一个稀疏向量，也就是不重要的特征权重值为0。第二个是L2正则化，也就是对求所有权重的平方和，导致的结果就是权重分散，鼓励每个特征都对最终判断有影响。说明一下，L1正则化更像是特征选择，选择出重要的特征，L2正则化更像是大众投票，防止某个特征权重值过大，一旦该特征发生一点改变，对结果影响过大。
         4. Dropout，这也是正则化的一种方法，它在训练过程中随机把一些神经元删除，也就是权重调整为0，这让模型变得简单，也就不容易过拟合。每一批次数据，由于随机性剔除神经元，使得网络具有一定的稀疏性，从而能减轻了不同特征之间的协同效应。而且由于每次被剔除的神经元不同，所以整个网络神经元的参数也只是部分被更新，消除减弱了神经元间的联合适应性，增强了神经网络的泛化能力和鲁棒性。Dropout只在训练时使用，作为一个超参数，然而在测试集时，并不能使用。
         5. 多任务学习。
      
   BN和LN的区别（高频）：BN指的是Batch Normalization，它是针对某个通道对所有batch进行归一化，目的是为了让数据强行保持0均值1方差的分布，可以有效避免后续梯度消失的情况。为什么要让某个通道的数据保持0均值1方差的分布，就是为了让模型能够正常更新参数，假如没有该操作，某个通道的数据都很小，当梯度回传的时候，该通道的参数就几乎不更新了。另外，使用了BN之后，参数的初始化就没有那么重要了。LN指的是Layer Normalization，它是针对每一个batch进行操作，让这一个batch的数据保持0均值1方差的分布。它的优势就在于不需要batchsize一致，但是在CNN上表现不如BN。
      BN的问题：
         1. batchsize必须固定。
         2. 太小的batch效果并不是很明显。
         3. batch太大的话，会很占内存。
         4. 如果各个样本长度不一致，就没有办法BN。
   
   拿到训练样本如何预处理：一般都是会进行数据归一化，也就是减去均值，除以方差，保证数据的分布是符合0均值1方差。对于某些特殊情况会进行PCA等。
   
   如何实现模型的剪枝和量化：剪枝，之前常常在决策树中使用，把一些不重要的删去来提高效率。在深度学习中，如果有大量的权重在0附近，这种时候可以把这些权值删去，以此压缩模型。而如何让大量的权重值在0附近，就用到之前说过的正则化方法，L1正则化会约束大量权重值在0附近。这种方法可以降低模型的大小，但是如果有大量卷积还是需要和0进行操作，则不一定会明显提高速度。同时由于大部分的权重值被调整到了0，则可以不用再记录所有的权重索引，只记录下不为0的权重索引+值的键值对方式即可。
      量化：为了进一步压缩已剪枝的模型，思路是把模型的参数进行进一步离散化，稀疏化。举个简单例子，原来大部分的值都集中在100，如果只记录这些值和中心点的偏移量，那么又可以让矩阵变得稀疏化。至于找中心的方法，可以使用k-means等等，包括在最后一次训练的时候，把各个点的梯度相加，再乘上学习率，再对应相减等等方法。
   
   ROC和AUC的概念和计算：这个在前面总结过，对于AUC来说比较简单，就是把所有样本统计一遍，看有多少样本分错。而ROC曲线则设计到了TP和FP，它的关键就在于模型将True样本分类为Positive与False样本分类为Positive的比例。
      AUC：AUC的含义为，当随机挑选一个正样本和一个负样本，根据当前的分类器计算得到的score将这个正样本排在负样本前面的概率。AUC，（Area Under Curve），被定义为ROC曲线下的面积，显然这个面积小于1，又因为ROC曲线一般都处于y=x这条直线的上方，所以AUC一般在0.5到1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。
   
   Resnet的主要思想，这个思想能解决的问题：残差网络的思想就是如果添加多个分类器，那么就算不能起到好的作用，也尽量能够维持之前的作用不变。ResNet的主要思想是在网络中增加了直连通道，允许原始输入信息直接传到后面的层中，看图非常明显，也就是如果后面的层性能不好，可以忽略。残差网络的思想允许把之前层的输入直接传到后面的层中，这样该神经网络只需要学习后一层和前一层的残差，所以叫残差网络。
      解决的问题：最大的问题就是可以去构建更深层的网络，之前的传统网络由于其会在卷积中不断损失信息，因此无法构建很深层的网络，而残差网络在一定程度上减轻了该问题，只需要学习其差值。
   
   shuffle net的主要思想，以及该思想是用于提升精度还是速度：该思想是通过群组卷积来提高卷积效率，因此主要是提升速度。
      它的思想和前文中深度卷积分离网络一样，首先是使用尺寸为1的卷积来减少通道，之后使用尺寸为3的卷积来卷积图像。但是，它针对尺寸为1的卷积，首先是进行了一个分组，之后每一个组进行卷积，这样可以降低计算量。但是如果直接接着分组卷积，就会导致某部分的输出只和部分输入有关，因此需要对其再进行一次分组，之后对小组再进行shuffle，这样可以保证，输出依然是和整体输入有关。
      
   YoLo和RCNN系列的主要区别，YoLo模型输出大小与每个输出位置的含义：两个最大的区别就是，YoLo是一阶段的，而RCNN是二阶段的，因此YoLo在相同提出时间时，效率高于RCNN但是精度不如RCNN。
      YoLov1： 最终模型输出的是30个参数，其中4*2+2+20，两个分类预测值，20个类别分数，两个框size。当然不同的YoLo版本输出的信息不完全一致。
   
   sigmoid和softmax的区别：
      sigmoid：Sigmoid =多标签分类问题=多个正确答案=非独占输出。Sigmoid函数是一种logistic函数，它将任意的值转换到[0, 1]。二者相互独立，可看作两次独立的实验，二者相加并不一定为1。
      softmax：Softmax =多类别分类问题=只有一个正确答案=互斥输出。构建分类器，解决只有唯一正确答案的问题时，用Softmax函数处理各个原始输出值。Softmax函数的分母综合了原始输出值的所有因素，这意味着，Softmax函数得到的不同概率之间相互关联。Softmax函数是二分类函数Sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。

   有几种卷积：
      1. 可变性卷积：可变形卷积顾名思义就是卷积的位置是可变形的，并非在传统的N × N的网格上做卷积，这样的好处就是更准确地提取到我们想要的特征（传统的卷积仅仅只能提取到矩形框的特征），在上面这张图里面，左边传统的卷积显然没有提取到完整绵羊的特征，而右边的可变形卷积则提取到了完整的不规则绵羊的特征。在可变形卷积的推理中，卷积核的参数值并没有发生改变，改变的是卷积核中每个参数的位置，相当于每次卷积时都需要事先得到一个与卷积核同参数量的偏移量矩阵，通过偏移量矩阵调整被卷积的数值，然后用卷积核进行常规卷积。
      2. 扩张卷积：扩张卷积（Dilated Convolution）也被称为空洞卷积或者膨胀卷积，是在标准的卷积核中注入空洞，以此来增加模型的感受野（reception field）。相比原来的正常卷积操作，除了卷积核大小，步长和填充外，扩张卷积多了一个参数：dilation rate，指的是卷积核的点的间隔数量，比如常规的卷积操作dilatation rate为1。扩张的卷积为卷积层引入另一个参数，称为扩张率。这定义了卷积核中值之间的间距。扩张率为2的3x3内核与5x5内核具有相同的视野，而仅使用9个参数。想象一下，获取一个5x5内核并删除每一个第二列和第二行（间隔删除）。
      3. 可分离卷积：可分离卷积主要有两种类型：空间可分离卷积和深度可分离卷积。

   numpy和torch中如何将行列倒置：都是直接.T即可。torch还可以使用permute。

   numpy和torch如何将不同维度调换：使用transpose即可。

   动态规划思想和解法：动态规划算法的基本思想是：将待求解的问题分解成若干个相互联系的子问题，先求解子问题，然后从这些子问题的解得到原问题的解；对于重复出现的子问题，只在第一次遇到的时候对它进行求解，并把答案保存起来，让以后再次遇到时直接引用答案，不必重新求解。动态规划算法将问题的解决方案视为一系列决策的结果，与贪婪算法不同的是，在贪婪算法中，每采用一次贪婪准则，便做出一个不可撤回的决策；而在动态规划算法中，还要考察每个最优决策序列中是否包含一个最优决策子序列，即问题是否具有最优子结构性质。动态规划的难点在于写出递推式。

   激活函数（CBAM中使用的是什么激活函数）：sigmoid，relu，leaky relu，tanh，elu，prelu，softmax，swish，softplus。CBAM中卷积使用的是leaky relu，而全连接神经网络当然是sigmoid。

   人脸检测的一些框架：MTCNN，face R-CNN，SSH。
   
   yolo中NMS流程：NMS 的本质是搜索局部极大值，抑制非极大值元素。
      1. 对所有预测框的置信度降序排序
      2. 选出置信度最高的预测框，确认其为正确预测，并计算他与其他预测框的 IOU
      3. 根据步骤2中计算的 IOU 去除重叠度高的，IOU > threshold 阈值就直接删除
      4. 剩下的预测框返回第1步，直到没有剩下的为止
      NMS 一次处理只会一个类别，所以如果有N个类别，那么就需要执行N次。
   ```

![image](https://user-images.githubusercontent.com/26198992/183623026-c6682bcd-23f5-4539-b41b-06031f255794.png)


6. NLP问题

   ```
   注意力机制如何实现，为什么要除以√d （高频）：
   拿到文本后先进行哪些预处理，怎样进行分词：
   怎样保证训练模型用的不同语料的词向量的维度，怎样设置BatchSize：
   Transformer模型的结构：
   Bert模型的结构，输入包括哪些部分：
   RNN和LSTM的区别，RNN会出现梯度消失的数学原理：
   ```

7. Pytorch问题

   ```
   数据集有哪几种类型，在线数据和离线数据使用时有何区别：一种是Map式数据集，一种是Iterable式数据集。离线数据就是要把数据全部储存在磁盘上，当数据增强时就把数据全部扩充好放在磁盘上，而在线数据就是在每个epoch训练前对数据集进行操作。
   cat和stack的区别：共同点在需要拼接的dim上都需要有相同的size，不同点cat是直接增加现有维度的值，stack则会增加一个维度，类似于堆叠，stack需要维度完全的一致。
   ```
   
8. 机器学习问题

   ```
   方差和偏差的区别：方差的含义：方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。 （2）偏差定义： 期望输出与真实标记的差别称为偏差（bias），即： 偏差的含义：偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。
   ```



排序3次（2次快速排序，1次面试官明确说冒泡排序），快速幂（主站50题）1次，IOU（主站223题）1次，二叉搜索树查找（主站700题）1次，手写2D卷积（主站661题类似）1次，还有一次是用迭代法实现f(x,y)=f(x-1,2*y)+y。


## linux常见问题
1. 无法删除有乱码文件名的文件。解决办法，使用ls -i来查询文件的node号，之后使用find命令来删除。
2. git对指定文件不进行追踪，使用git rm --cached 文件名，这样可以不删除本地文件，push之后可以让该文件不被追踪。


## mongodb问题
python可变数据结构导致问题，在插入数据的时候，为了防止有重复的键，使用了try，结果程序在运行的时候自己加了_id字段导致后续一直更新出错。

## DBSCAN
dbscan是一个常见的聚类算法，它的优势就是可以根据密度进行聚类，在这里有设计到KNN的思想可以进行参考。
https://github.com/Eleobert/dbscan/blob/master/dbscan.cpp
https://blog.csdn.net/k76853/article/details/50440182
https://www.cnblogs.com/pinard/p/6208966.html
https://www.cnblogs.com/pinard/p/6061661.html
https://en.wikipedia.org/wiki/DBSCAN

## python论坛
https://github.com/vicalloy/lbforum-site

## 相关系数
Pearson相关系数：它适用于线性结构，且不会根据值相对变化而发生改变。
Spearman相关系数：它主要是看两组数据是否有相同的变化趋势，而不管是否线性。
Kerndel相关系数：结合。

## yolo
yolo是目标检测的算法，you only look once，是一阶段的目标检测算法，之前的MTCNN就是一个二阶段的目标检测。一般来说一阶段的算法速度会比二阶段要快，而二阶段的精确度会比一阶段要高。yolo整体来说还是比较复杂的，其实它的backbone并不复杂，仔细看过来其实可以随便的替换darknet53或者resnet都可以。最后是三个大小的输出。下面来介绍一下。

### darknet
实际上resent的变形，主要的堆叠模块还是3*3，下面是它的网络结构。

![image](https://pic4.zhimg.com/80/v2-eeee97586625ee52e073411c286d4d33_720w.webp)

整体的结构可以看到和resnet基本一致，都是使用基础3×3模块，同时使用1×1的模块来调整通道数，去掉了最后的全局平均和全连接层用来当作yolo3的backbone。其实yolo3的backbone完全是可以随便变化的，只要能够得到对应尺寸即可。如果本身的维度不多，完全可以换成较小的网络。因此yolo3最重要的实际上loss的计算。

### yolo
前面说过yolo的backbone这里可以看到中间就是主干网络，而在不同的位置会进行输出。yolo3最大的改进就是多了多尺度的预测，不仅是anchor有多尺度，本身网络就会输出不同大小的图像来预测。从图中可以看到，第一个输出的尺寸是13×13，在输出26×26尺寸之前把13×13尺寸的输出进行了上采样，这是为了26×26尺寸中有更多有用的信息，同理52×52也采用了该方法。网络上的搭建并不复杂，并且这里是否进行上采样以及是否进行concatenate都可以自己选择，我认为yolo3最大的改进是在loss方面，下面重点介绍loss。

![image](https://pic4.zhimg.com/v2-edabcf6c621d8f416fffa5df0c5b2533_r.jpg)

#### yolo-loss
目标检测最困难的问题其实就是loss计算，对于前面backbone的搭建只要理解就可以自由变换成自己需要的任意一个网络。而对于loss则不是那么容易的。下面这张图可以看到yolov3的损失分为三个部分，第一个就是xywh的损失，该损失在初版是使用均方误差来进行衡量，后面有人改进为GIOU的计算方法。第二个损失是该框是否存在物体的损失，实际上使用的是交叉熵损失，只有两种有框或者无框。第三个损失是分类损失，使用的是BCE损失，这里是为了能够进行多种类的识别。
![image](https://user-images.githubusercontent.com/26198992/209527622-436c46a0-6e7e-4e1e-8dd9-6968c9e03c04.png)

这里有一个最关键的地方，之前是一直都没有搞懂为什么别人的loss计算只计算正样本损失，负样本损失实际上是不进行衡量的。其实原因是，在构建样本对应的标签时，如果一张图片上有多个样本则该图片会反复出现。这样就可以保证只计算正样本损失也能够迭代框的loss，这种是不可以去计算负样本，因为一张图片中的样本数量并不确定，不能简单的把所有其他位置都标为负样本。

## 计算机原理
浮点数转二进制：https://zhuanlan.zhihu.com/p/137616403
